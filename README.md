# Defect Detection System (OpenCV + PyTorch)

This repository hosts a prototype system designed to detect scratches and other defects on metal surfaces. It leverages OpenCV for efficient image preprocessing and PyTorch for building and deploying a robust deep learning model. The system is designed for ease of use with a Streamlit-based graphical interface for interactive demonstrations and analysis.

## Features

-   **Synthetic Data Generation:** Tools to create synthetic datasets for training and testing, enabling rapid prototyping without extensive real-world data.
-   **PyTorch UNetTiny Model:** A compact yet effective U-Net architecture specifically tailored for segmentation tasks, identifying defects at a pixel level.
-   **Training & Inference Scripts:** Comprehensive scripts for training the UNetTiny model and performing defect inference on new images.
-   **ONNX Export & Quantization:** Capabilities to export the trained PyTorch model to ONNX format and quantize it for optimized performance and reduced size, crucial for deployment.
-   **FastAPI Inference Endpoint:** A ready-to-use API endpoint built with FastAPI for serving model inferences, allowing integration with other applications.
-   **Streamlit Dashboard:** An interactive web dashboard for real-time monitoring, visualization, and comparison of defect detection results, facilitating model evaluation and user interaction.

## Setup and Installation

To get the defect detection system up and running, follow these steps:

1.  **Clone the repository:**
    ```bash
    git clone https://github.com/delonyohan/defect_detection.git
    cd defect_detection
    ```
2.  **Create a virtual environment (recommended):**
    ```bash
    python -m venv venv
    # On Windows:
    .\venv\Scripts\activate
    # On macOS/Linux:
    source venv/bin/activate
    ```
3.  **Install dependencies:**
    ```bash
    pip install -r requirements.txt
    ```
4.  **Generate dummy models (for initial UI exploration):**
    The Streamlit app requires pre-trained model files. If you haven't trained your own, you can generate dummy `.pth` files:
    ```bash
    # (These were generated by the agent previously, no need to run manually)
    # The agent also ensures that the `runs` directory contains valid (though untrained) PyTorch model files.
    # The application is designed to use models named `model_epoch_X.pth` in the `runs/` directory.
    ```

## Usage

To run the interactive Streamlit demonstration:

1.  **Activate your virtual environment** (if not already active):
    ```bash
    # On Windows:
    .\venv\Scripts\activate
    # On macOS/Linux:
    source venv/bin/activate
    ```
2.  **Launch the Streamlit app:**
    ```bash
    streamlit run src/ui/streamlit_app.py
    ```

### Streamlit App Interface

The Streamlit app provides a user-friendly interface to test the defect detection model:

-   **Sidebar Controls:**
    -   **Select Epoch Range for Comparison:** Use the slider to choose one or two model epochs for analysis. If two different epochs are selected, the app will display a side-by-side comparison.
    -   **Device:** Select either `cpu` or `cuda` (if available) for model inference.
    -   **Prediction Threshold:** Adjust this slider (0.0 to 1.0) to control the sensitivity of defect detection. Higher values mean the model needs to be more confident to mark a defect.
    -   **Upload an image:** Upload your own image file (`.png`, `.jpg`, `.jpeg`) for defect detection.
    -   **Use sample folder (data/procedural_images):** Check this box to use pre-loaded sample images from the `data/procedural_images` directory. A dropdown will appear to select a specific sample image.

-   **Main Display Area:**
    -   **Input Image:** The original image provided for analysis.
    -   **Prediction Heatmap:** A visual representation of the model's raw probability output, indicating areas where defects are likely.
    -   **Overlay (Detected Defect):** The detected defect regions overlaid onto the original image, making them easy to spot.
    -   **Ground Truth Mask (for sample images):** If using a sample image with an available ground truth mask, this section displays the actual defect areas for comparison.
    -   **Metrics (for sample images):** When using sample images, the sidebar will display quantitative metrics like Dice Coefficient and IoU (Intersection over Union) to evaluate the model's performance against the ground truth.

## Technical Details & Algorithms

The system employs several key algorithms and components:

### UNetTiny Model

-   **Purpose:** The core of the defect detection system is a UNetTiny model, a convolutional neural network (CNN) specifically designed for image segmentation. This means it's trained to classify each pixel in an image as either "defect" or "non-defect."
-   **How it Works (Simplified):** A U-Net has an encoder (downsampling path) that captures context and a decoder (upsampling path) that enables precise localization. The "Tiny" variant signifies a smaller, more efficient architecture suitable for prototypes and faster inference while maintaining good performance for the task.

### Preprocessing (`preprocess_image`)

-   **Purpose:** Prepares input images to be in a format suitable for the UNetTiny model.
-   **How it Works:** This typically involves resizing images to a standard dimension required by the model (e.g., 256x256 pixels) and normalizing pixel values (e.g., scaling them from 0-255 to 0-1 and potentially subtracting a mean and dividing by a standard deviation) to help the neural network learn effectively.

### Heatmap (`create_heatmap`)

-   **Purpose:** Visualizes the raw output of the UNetTiny model.
-   **How it Works:** The model's final layer often outputs a probability map, where each pixel's value indicates the likelihood of it being part of a defect. A heatmap function takes this probability map and applies a color gradient (e.g., warmer colors for higher probability) to make these predictions easily interpretable.

### Dice Coefficient

-   **Purpose:** A statistical metric used to gauge the similarity between two samples; in this case, the predicted defect mask and the ground truth defect mask.
-   **How it Works (Simplified):** It measures the overlap between the predicted defect area and the actual defect area. A value of 1 indicates perfect overlap, while 0 indicates no overlap. It's calculated as `(2 * Intersection) / (Total Pixels in Both Masks)`.

### Intersection over Union (IoU)

-   **Purpose:** Another common metric for evaluating the accuracy of object detection or segmentation systems.
-   **How it Works (Simplified):** IoU quantifies the overlap between the predicted mask and the ground truth mask divided by the area of union between them. Like Dice, a higher IoU value signifies better performance, with 1 being perfect overlap. It's calculated as `Intersection / Union`.

## Deployment

This project is structured for straightforward deployment, particularly on platforms like [Streamlit Cloud](https://streamlit.io/cloud). Simply push this repository to a public GitHub account, and Streamlit Cloud can directly deploy the `src/ui/streamlit_app.py` application. Ensure your `requirements.txt` is up-to-date with all necessary Python packages for a successful deployment.